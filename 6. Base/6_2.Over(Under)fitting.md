# Overfitting 과 Underfitting 정의 

## Overfitting (과적합)
![image](https://github.com/user-attachments/assets/b8723bc1-0fd9-4f36-bd1a-d989f09cecde)

- 학습 데이터에 대해 괗하게 학습된 경우를 말함
  - 학습 데이터가 부족할 때
  - Feature(특성)이 모델에 비해 복잡할 떄 일어난다. 

# 원인
* Model Capacity : 모델의 용량을 늘리려면 Layer를 더 Deep하게 쌓거나 Layer랑 hidden Unit 개수를 늘리면 된다.
  * 이로 인해 과적합 현상이 발생

# 해결책 
 * Model Capacity 낮추기 : 모델이 학습 데이터에 비해 과하게 복잡하지 않게 Hidden Layer와 Layer 개수를 줄인다.
 * DropOut : 학습 중에 무작위 일부 뉴런을 Drop 하여 활성화 시키지 않는다.
 * Regularization : L1 정규화 가중치의 절대값 합계를 최소화하고, L2 정규화는 가중치의 제곱합을 최소화한다. 
   * 이유 : 모델이 학습 데이터에 치우치지 않고, 일반화된 패턴을 학습하도록 유도
 * Data Augmentation : 데이터 증강을 통해 학습 데이터량을 늘린다. 


## Underfitting 
* Underfitting은 이미 있는 Train Set도 학습을 하지 못한 상태를 의미 한다.

# 발생 이유 
* 학습 반복 횟수가 너무 적음
* 데이터의 특성에 비해 모델이 간단함
* 데이터 양이 너무 적음

-------------------

## 학습 단위 Epoch, Batch size, Iteration

# Epoch 
* 훈련 데이터셋에 포함된 모든 데이터들이 한번씩 모델을 통과한 횟수로, 모든 학습 데이터셋을 학습하는 횟수를 의미
# Batch Size
* 연산 한 번에 들어가는 데이터의 크기를 가리킨다. 
* 1Batch size에 해당되는 데이터셋을 mini Batch라 한다.
# Iteration 
* 전체 데이터를 모델에 한번 학습시키는데 필요한 배치의 수를 말한다.




